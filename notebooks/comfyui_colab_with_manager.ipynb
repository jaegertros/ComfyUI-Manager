{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaaaaaaaaa"
   },
   "source": "# ComfyUI + Manager — Optimized Colab Setup\n\n**Performance optimizations:**\n- Installs to **local SSD** (not Google Drive) for fast git/pip operations\n- Skips redundant PyTorch install (Colab already has it)\n- Single combined pip install instead of 5 separate calls\n- Shallow git clones (`--depth 1`)\n- Pip cache persisted on Google Drive for faster repeat sessions\n- Custom nodes backup/restore via tarball on Drive\n- **Model dirs symlinked to Google Drive** — downloads via Manager go directly to Drive and persist across sessions\n\n**First run:** ~10-15 min | **Repeat runs (with backup):** ~2-5 min"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbbbbbbbbb"
   },
   "outputs": [],
   "source": "#@title Environment Setup\nimport os, shutil, time\n\n# ============================================================\n# Configuration\n# ============================================================\nUSE_GOOGLE_DRIVE = True          #@param {type:\"boolean\"}\nUPDATE_COMFY_UI = True           #@param {type:\"boolean\"}\nUSE_COMFYUI_MANAGER = True       #@param {type:\"boolean\"}\nRESTORE_CUSTOM_NODES = True      #@param {type:\"boolean\"}\nINSTALL_CUSTOM_NODES_DEPS = True #@param {type:\"boolean\"}\n\n# Paths — edit these to match your Drive layout\nDRIVE_MODELS_ROOT = \"/content/drive/MyDrive/AI/models\"\nDRIVE_COMFYUI_PERSIST = \"/content/drive/MyDrive/AI/models/COMFYUI\"\nLOCAL_WORKSPACE = \"/content/ComfyUI\"   # local SSD — fast!\nPIP_CACHE_DIR = \"/content/drive/MyDrive/AI/.pip-cache\"\n\n_start = time.time()\n\n# ============================================================\n# 1. Mount Google Drive & set pip cache\n# ============================================================\nif USE_GOOGLE_DRIVE:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    os.makedirs(PIP_CACHE_DIR, exist_ok=True)\n    os.environ['PIP_CACHE_DIR'] = PIP_CACHE_DIR\n    os.makedirs(DRIVE_COMFYUI_PERSIST, exist_ok=True)\n\n# ============================================================\n# 2. Load Colab secrets (HF, CivitAI, ngrok)\n# ============================================================\ntry:\n    from google.colab import userdata\n    _hf = userdata.get('HF_TOKEN')\n    if _hf:\n        os.environ['HF_TOKEN'] = _hf\n        os.environ['HUGGING_FACE_HUB_TOKEN'] = _hf\n        print(\"HF_TOKEN loaded\")\n    _civit = userdata.get('CIVIT_TOKEN')\n    if _civit:\n        os.environ['CIVIT_TOKEN'] = _civit\n        print(\"CIVIT_TOKEN loaded\")\n    _ngrok = userdata.get('NGROK_AUTHTOKEN')\n    if _ngrok:\n        os.environ['NGROK_AUTHTOKEN'] = _ngrok\n        print(\"NGROK_AUTHTOKEN loaded\")\nexcept Exception:\n    print(\"Could not load Colab secrets — set them in Colab sidebar > Secrets\")\n\n# ============================================================\n# 3. Clone / update ComfyUI on local SSD (fast!)\n# ============================================================\nif not os.path.isdir(LOCAL_WORKSPACE):\n    print(\"=== Cloning ComfyUI (shallow) ===\")\n    !git clone --depth 1 https://github.com/comfyanonymous/ComfyUI {LOCAL_WORKSPACE}\nelif UPDATE_COMFY_UI:\n    print(\"=== Updating ComfyUI ===\")\n    !cd {LOCAL_WORKSPACE} && git pull\n\n%cd {LOCAL_WORKSPACE}\n\n# Set COMFYUI_PATH so cm-cli.py knows where ComfyUI lives\nos.environ['COMFYUI_PATH'] = LOCAL_WORKSPACE\n\n# ============================================================\n# 3b. Symlink model dirs → Google Drive (downloads go to Drive!)\n# ============================================================\n# This replaces default model dirs with symlinks so that ALL\n# model downloads (via Manager install, custom nodes, etc.)\n# automatically land on Google Drive and persist across sessions.\nMODEL_SYMLINKS = {\n    'checkpoints':      f'{DRIVE_MODELS_ROOT}/checkpoints',\n    'vae':              f'{DRIVE_MODELS_ROOT}/vae',\n    'loras':            f'{DRIVE_MODELS_ROOT}/loras',\n    'controlnet':       f'{DRIVE_MODELS_ROOT}/controlnet',\n    'clip':             f'{DRIVE_MODELS_ROOT}/clip',\n    'embeddings':       f'{DRIVE_MODELS_ROOT}/embeddings',\n    'gligen':           f'{DRIVE_MODELS_ROOT}/gligen',\n    'upscale_models':   f'{DRIVE_MODELS_ROOT}/upscale_models',\n    'style_models':     f'{DRIVE_MODELS_ROOT}/style_models',\n    'diffusion_models': f'{DRIVE_MODELS_ROOT}/diffusion_base',\n    'text_encoders':    f'{DRIVE_MODELS_ROOT}/text_encoders',\n}\n\nif USE_GOOGLE_DRIVE:\n    print(\"=== Linking model dirs to Google Drive ===\")\n    models_dir = os.path.join(LOCAL_WORKSPACE, 'models')\n    for folder, drive_target in MODEL_SYMLINKS.items():\n        local_path = os.path.join(models_dir, folder)\n        os.makedirs(drive_target, exist_ok=True)\n        if os.path.islink(local_path):\n            os.remove(local_path)\n        elif os.path.isdir(local_path):\n            shutil.rmtree(local_path)\n        os.symlink(drive_target, local_path)\n        print(f\"  {folder}/ -> {drive_target}\")\n\n# ============================================================\n# 4. Install Python dependencies\n# ============================================================\n# Colab already has PyTorch + CUDA — install everything else from\n# ComfyUI's own requirements.txt so we stay current with new deps.\nprint(\"=== Installing ComfyUI dependencies ===\")\n!pip install -q -r requirements.txt GitPython\n\n# ============================================================\n# 5. Install ComfyUI-Manager on local SSD\n# ============================================================\nif USE_COMFYUI_MANAGER:\n    _mgr = os.path.join(LOCAL_WORKSPACE, \"custom_nodes\", \"ComfyUI-Manager\")\n    if not os.path.isdir(_mgr):\n        print(\"=== Cloning ComfyUI-Manager (shallow) ===\")\n        !git clone --depth 1 https://github.com/ltdrdata/ComfyUI-Manager {_mgr}\n    elif UPDATE_COMFY_UI:\n        !cd {_mgr} && git pull\n\n# ============================================================\n# 6. Restore custom nodes backup from Drive (if available)\n# ============================================================\n_backup = os.path.join(DRIVE_COMFYUI_PERSIST, \"custom_nodes_backup.tar.gz\")\n_custom_dir = os.path.join(LOCAL_WORKSPACE, \"custom_nodes\")\nif RESTORE_CUSTOM_NODES and os.path.isfile(_backup):\n    print(\"=== Restoring custom nodes from Drive backup ===\")\n    !cd {LOCAL_WORKSPACE} && tar xzf {_backup}\n    print(f\"Restored from {_backup}\")\nelif RESTORE_CUSTOM_NODES:\n    print(\"No custom nodes backup found — will start fresh.\")\n    print(f\"  (Run the 'Save Custom Nodes Backup' cell later to create one)\")\n\n# ============================================================\n# 7. Install custom node dependencies\n# ============================================================\nif INSTALL_CUSTOM_NODES_DEPS and USE_COMFYUI_MANAGER:\n    print(\"=== Installing custom node dependencies ===\")\n    !cd {LOCAL_WORKSPACE} && python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n\n# ============================================================\n# 8. Write extra_model_paths.yaml (non-standard types only)\n# ============================================================\n# Standard model types (checkpoints, vae, loras, etc.) are handled\n# by symlinks above. This YAML only covers custom types that don't\n# have a default ComfyUI model directory.\n_yaml_path = os.path.join(LOCAL_WORKSPACE, \"extra_model_paths.yaml\")\n_yaml_content = f\"\"\"# Auto-generated — standard model dirs use symlinks to Drive\n# This file only covers non-standard model types\ngoogle_drive:\n    base_path: {DRIVE_MODELS_ROOT}/\n    LLM: llm/\n    audio: audio_models/\n\"\"\"\nwith open(_yaml_path, 'w') as f:\n    f.write(_yaml_content)\nprint(f\"Wrote {_yaml_path}\")\n\n# ============================================================\n# Done!\n# ============================================================\n_elapsed = time.time() - _start\nprint(f\"\\n{'='*50}\")\nprint(f\"Setup complete in {_elapsed:.0f}s ({_elapsed/60:.1f} min)\")\nprint(f\"Workspace: {LOCAL_WORKSPACE}\")\nprint(f\"Models:    {DRIVE_MODELS_ROOT}/ (via symlinks)\")\nprint(f\"{'='*50}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cccccccccc"
   },
   "source": "### Download models to Google Drive (optional)\nModels are saved to your Drive so they persist across sessions. Uses your HF_TOKEN and CIVIT_TOKEN for gated/authenticated downloads. Uncomment the models you want."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dddddddddd"
   },
   "outputs": [],
   "source": "import os\n\nMODELS = \"/content/drive/MyDrive/AI/models\"\nHF_AUTH = f'--header=\"Authorization: Bearer {os.environ.get(\"HF_TOKEN\", \"\")}\"' if os.environ.get(\"HF_TOKEN\") else \"\"\nCIVIT_TOKEN = os.environ.get(\"CIVIT_TOKEN\", \"\")\n\n# ---- Checkpoints ----\n\n# SD1.5\n#!wget -c {HF_AUTH} https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P {MODELS}/checkpoints/\n\n# SDXL (recommended workflows: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/)\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P {MODELS}/checkpoints/\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P {MODELS}/checkpoints/\n\n# SD2\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P {MODELS}/checkpoints/\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P {MODELS}/checkpoints/\n\n# SDXL ReVision\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P {MODELS}/clip/\n\n# ---- VAE ----\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P {MODELS}/vae/\n\n# ---- LoRAs ----\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P {MODELS}/loras/\n\n# CivitAI LoRAs (uses your CIVIT_TOKEN)\n#!wget -c --content-disposition \"https://civitai.com/api/download/models/10350?token={CIVIT_TOKEN}\" -P {MODELS}/loras/\n#!wget -c --content-disposition \"https://civitai.com/api/download/models/10638?token={CIVIT_TOKEN}\" -P {MODELS}/loras/\n\n# ---- ControlNet ----\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P {MODELS}/controlnet/\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P {MODELS}/controlnet/\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P {MODELS}/controlnet/\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P {MODELS}/controlnet/\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P {MODELS}/controlnet/\n\n# ControlNet SDXL\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P {MODELS}/controlnet/\n#!wget -c {HF_AUTH} https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P {MODELS}/controlnet/\n\n# ---- GLIGEN ----\n#!wget -c {HF_AUTH} https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P {MODELS}/gligen/\n\n# ---- Upscale models ----\n#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P {MODELS}/upscale_models/\n#!wget -c {HF_AUTH} https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P {MODELS}/upscale_models/\n#!wget -c {HF_AUTH} https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P {MODELS}/upscale_models/\n\n# ---- Style models ----\n#!wget -c {HF_AUTH} https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P {MODELS}/style_models/\n\n# ---- CLIP Vision ----\n#!wget -c {HF_AUTH} https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O {MODELS}/clip/clip_vit14.bin\n\nprint(\"Model downloads complete.\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Save Custom Nodes Backup to Google Drive\nRun this cell **after installing new custom nodes** via the Manager UI to persist them across Colab sessions. The backup is a single tarball — much faster to restore than re-cloning everything.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os, time\n\nLOCAL_WORKSPACE = \"/content/ComfyUI\"\nDRIVE_COMFYUI_PERSIST = \"/content/drive/MyDrive/AI/models/COMFYUI\"\n_backup = os.path.join(DRIVE_COMFYUI_PERSIST, \"custom_nodes_backup.tar.gz\")\n\nos.makedirs(DRIVE_COMFYUI_PERSIST, exist_ok=True)\n\nprint(\"=== Saving custom nodes backup to Google Drive ===\")\n_t = time.time()\n!cd {LOCAL_WORKSPACE} && tar czf {_backup} custom_nodes/\n_sz = os.path.getsize(_backup) / (1024*1024)\nprint(f\"Saved {_sz:.0f} MB to {_backup} in {time.time()-_t:.0f}s\")\nprint(\"This backup will be restored automatically on your next session.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Run ComfyUI with ngrok (Recommended)\nRequires `NGROK_AUTHTOKEN` in Colab Secrets. Get a free token at [ngrok.com](https://dashboard.ngrok.com/signup). More reliable than cloudflared and gives you a stable URL.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os, subprocess, threading, time, socket\n\n!pip install -q pyngrok\n\ndef ngrok_tunnel(port):\n    while True:\n        time.sleep(0.5)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex(('127.0.0.1', port))\n        if result == 0:\n            break\n        sock.close()\n\n    from pyngrok import ngrok\n    token = os.environ.get('NGROK_AUTHTOKEN', '')\n    if not token:\n        print(\"ERROR: NGROK_AUTHTOKEN not set. Add it to Colab Secrets.\")\n        return\n    ngrok.set_auth_token(token)\n    tunnel = ngrok.connect(port)\n    print(f\"\\nComfyUI is ready! Access it at: {tunnel.public_url}\\n\")\n\nthreading.Thread(target=ngrok_tunnel, daemon=True, args=(8188,)).start()\n\n!cd /content/ComfyUI && python main.py --dont-print-server",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkkkkkkkkkkkkkk"
   },
   "source": "### Run ComfyUI with cloudflared (Alternative)\nUse this if you don't have an ngrok account. No signup required — uses temporary Cloudflare tunnel URLs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjjjjjjjjjjjjj"
   },
   "outputs": [],
   "source": "!wget -q -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n!dpkg -i ~/cloudflared-linux-amd64.deb > /dev/null 2>&1\n\nimport subprocess, threading, time, socket\n\ndef cloudflared_tunnel(port):\n    while True:\n        time.sleep(0.5)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex(('127.0.0.1', port))\n        if result == 0:\n            break\n        sock.close()\n    print(\"\\nComfyUI finished loading, launching cloudflared tunnel...\\n\")\n    p = subprocess.Popen(\n        [\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"],\n        stdout=subprocess.PIPE, stderr=subprocess.PIPE\n    )\n    for line in p.stderr:\n        l = line.decode()\n        if \"trycloudflare.com \" in l:\n            print(\"ComfyUI URL:\", l[l.find(\"http\"):], end='')\n\nthreading.Thread(target=cloudflared_tunnel, daemon=True, args=(8188,)).start()\n\n!cd /content/ComfyUI && python main.py --dont-print-server"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkkkkkkkkkkkkk"
   },
   "source": "### Run ComfyUI with localtunnel (Alternative)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjjjjjjjjjjjj"
   },
   "outputs": [],
   "source": "!npm install -g localtunnel\n\nimport subprocess, threading, time, socket, urllib.request\n\ndef localtunnel_thread(port):\n    while True:\n        time.sleep(0.5)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex(('127.0.0.1', port))\n        if result == 0:\n            break\n        sock.close()\n    print(\"\\nComfyUI finished loading, launching localtunnel...\\n\")\n    print(\"The password/endpoint ip for localtunnel is:\",\n          urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n    p = subprocess.Popen([\"lt\", \"--port\", str(port)], stdout=subprocess.PIPE)\n    for line in p.stdout:\n        print(line.decode(), end='')\n\nthreading.Thread(target=localtunnel_thread, daemon=True, args=(8188,)).start()\n\n!cd /content/ComfyUI && python main.py --dont-print-server"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gggggggggg"
   },
   "source": "### Run ComfyUI with Colab iframe (Fallback)\nUse only if tunnels above don't work. Note: live image previews won't work because the Colab iframe blocks WebSockets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhhhhhhhhh"
   },
   "outputs": [],
   "source": "import threading, time, socket\n\ndef iframe_thread(port):\n    while True:\n        time.sleep(0.5)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex(('127.0.0.1', port))\n        if result == 0:\n            break\n        sock.close()\n    from google.colab import output\n    output.serve_kernel_port_as_iframe(port, height=1024)\n    print(\"To open in a separate window:\")\n    output.serve_kernel_port_as_window(port)\n\nthreading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n\n!cd /content/ComfyUI && python main.py --dont-print-server"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}